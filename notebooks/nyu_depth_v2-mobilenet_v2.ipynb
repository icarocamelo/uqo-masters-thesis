{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be43cdc1-84f6-4aa7-958f-6289dc759958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0+nv23.1)\n",
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (67.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20.0; python_version >= \"3.7\" in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.1)\n",
      "Collecting array-record\n",
      "  Downloading array_record-0.4.0-py38-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 10.3 MB/s eta 0:00:01     |████████████████▌               | 1.6 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 4.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting etils[enp,epath]>=0.9.0\n",
      "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (5.9.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (2.28.2)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 2.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from tensorflow_datasets) (5.10.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: zipp; extra == \"epath\" in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow_datasets) (3.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2022.12.7)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.59.1-py2.py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "Building wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21485 sha256=7f3a7cf4bb1f94a6bf86d079f1becdbe029097b8150b9e59c341da6f90dbb33e\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built promise\n",
      "Installing collected packages: etils, array-record, click, dm-tree, promise, googleapis-common-protos, tensorflow-metadata, toml, tqdm, tensorflow-datasets\n",
      "Successfully installed array-record-0.4.0 click-8.1.3 dm-tree-0.1.8 etils-1.3.0 googleapis-common-protos-1.59.1 promise-2.3 tensorflow-datasets-4.9.2 tensorflow-metadata-1.13.1 toml-0.10.2 tqdm-4.65.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe66a6fb-1774-41f8-aae5-5214b098fbcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-22 16:36:46.031669: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 31.92 GiB (download: 31.92 GiB, generated: 74.03 GiB, total: 105.95 GiB) to /root/tensorflow_datasets/nyu_depth_v2/0.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd61d2a822c844a399fafc917e9451c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3802324125944b22b6ca4e6c263067aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c11610c6424417b268ce28b78d3ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_629/4258777829.py\", line 5, in <module>\n",
      "    dataset, info = tfds.load('nyu_depth_v2', split='train', with_info=True)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 169, in __call__\n",
      "    return function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/load.py\", line 640, in load\n",
      "    _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/load.py\", line 499, in _download_and_prepare_builder\n",
      "    dbuilder.download_and_prepare(**download_and_prepare_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/logging/__init__.py\", line 169, in __call__\n",
      "    return function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 646, in download_and_prepare\n",
      "    self._download_and_prepare(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/dataset_builder.py\", line 1498, in _download_and_prepare\n",
      "    split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/datasets/nyu_depth_v2/nyu_depth_v2_dataset_builder.py\", line 45, in _split_generators\n",
      "    base_path = dl_manager.download_and_extract(_URL)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 687, in download_and_extract\n",
      "    return _map_promise(self._download_extract, url_or_urls)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 830, in _map_promise\n",
      "    res = tree_utils.map_structure(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tree/__init__.py\", line 435, in map_structure\n",
      "    [func(*args) for args in zip(*map(flatten, structures))])\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tree/__init__.py\", line 435, in <listcomp>\n",
      "    [func(*args) for args in zip(*map(flatten, structures))])\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/download/download_manager.py\", line 831, in <lambda>\n",
      "    lambda p: p.get(), all_promises\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/promise/promise.py\", line 511, in get\n",
      "    self._wait(timeout or DEFAULT_TIMEOUT)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/promise/promise.py\", line 506, in _wait\n",
      "    self.wait(self, timeout)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/promise/promise.py\", line 502, in wait\n",
      "    async_instance.wait(promise, timeout)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/promise/async_.py\", line 117, in wait\n",
      "    target.scheduler.wait(target, timeout)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/promise/schedulers/immediate.py\", line 25, in wait\n",
      "    waited = e.wait(timeout)\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 558, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 799, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 845, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the NYU depth V2 dataset\n",
    "dataset, info = tfds.load('nyu_depth_v2', split='train', with_info=True)\n",
    "\n",
    "# Preprocess the dataset\n",
    "def preprocess_data(data):\n",
    "    image = tf.image.resize(data['image'], (224, 224))  # Resize image to match model input shape\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    depth = tf.cast(data['depth'], tf.float32) / 10.0  # Normalize depth values\n",
    "    return image, depth\n",
    "\n",
    "# Apply preprocessing to the dataset using from_generator\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: dataset,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 224, 224, 1), dtype=tf.float32)\n",
    "    )\n",
    ").map(preprocess_data)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * info.splits['train'].num_examples)\n",
    "train_dataset = train_dataset.take(train_size)\n",
    "val_dataset = train_dataset.skip(train_size)\n",
    "\n",
    "# Configure batch size and prefetching\n",
    "batch_size = 2\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431456bb-41f6-46f9-bc45-f5813a4798ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MobileNetV2 model\n",
    "base_model = tf.keras.applications.MobileNetV2(include_top=False, input_shape=(224, 224, 3))  # Update input shape\n",
    "\n",
    "# Freeze the base model's layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add a custom output layer for depth prediction\n",
    "output_layer = tf.keras.layers.Conv2D(1, 3, activation='relu', padding='same')(base_model.output)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# Define loss function and metrics\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751a6bda-9cad-408b-9849-ab47d721f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 1\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b4f2c-4e42-4c05-b984-4fa129b6cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('mobilenetv2_nyu_depth_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
